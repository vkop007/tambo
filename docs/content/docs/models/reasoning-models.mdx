---
title: Reasoning Models
description: Configure and use advanced reasoning capabilities in models that show their thinking process.
---

Reasoning models are specialized LLMs that expose their internal thought process before generating a final response. These models excel at complex tasks requiring multi-step reasoning, problem-solving, and logical analysis by spending additional compute time "thinking" through the problem.

<Callout type="info" title="Supported Providers">
  Tambo currently supports reasoning capabilities for **OpenAI** and **Google
  Gemini** models. Each provider uses different parameter names to control
  reasoning behavior.
</Callout>

## Provider-Specific Documentation

For detailed information about reasoning parameters and configuration for each provider, see:

- **[OpenAI Models](/reference/providers/openai#provider-specific-parameters)** - Configure `reasoningEffort` and `reasoningSummary` for GPT-5, O3, and other OpenAI reasoning models
- **[Google Models](/reference/providers/google#provider-specific-parameters)** - Configure `thinkingConfig` for Gemini 3.0 Pro, Deep Think, and other Gemini reasoning models

## What Are Reasoning Models?

Traditional LLMs generate responses token-by-token in a single forward pass. Reasoning models add an intermediate "thinking" phase where the model:

1. **Analyzes the problem** - Breaks down complex queries into sub-problems
2. **Explores solutions** - Considers multiple approaches and their tradeoffs
3. **Verifies reasoning** - Checks its logic before committing to an answer
4. **Generates response** - Produces the final output based on verified reasoning

This thinking process is captured as **reasoning tokens** that you can access, display, and analyze alongside the final response.

## Supported Models

See the provider-specific pages for complete model lists:

- **[OpenAI Models](/reference/providers/openai)** - GPT-5, GPT-5.1, GPT-5 Mini, GPT-5 Nano, GPT-4.1 Nano, O3, and more
- **[Google Models](/reference/providers/google)** - Gemini 3.0 Pro, Deep Think, 2.5 Pro, 2.5 Flash, and more

For configuration instructions and parameter details, see the **Provider-Specific Parameters** sections on each provider page.

## When to Use Reasoning Models

Reasoning models work best for tasks that benefit from step-by-step thinking:

**✅ Best for:**

- Complex problem-solving and analysis
- Mathematical calculations and proofs
- Code review and debugging
- Strategic planning requiring multiple steps
- Tasks where showing work builds user trust

**⚠️ Not ideal for:**

- Simple Q&A or fact retrieval
- Real-time chat requiring instant responses
- High-volume, cost-sensitive applications

## Displaying Reasoning in Your App

Tambo components automatically handle reasoning display - no additional code required.

### Built-in Support

When you add Tambo components from the CLI, reasoning support is included out-of-the-box:

```bash
npx tambo add message
```

These components include the `ReasoningInfo` sub-component that:

- **Auto-displays** reasoning in a collapsible dropdown
- **Shows thinking progress** with step counts during streaming
- **Auto-collapses** when the final response arrives
- **Auto-scrolls** to follow reasoning as it streams

<Callout type="tip" title="Zero Configuration">
  If you're using Tambo's pre-built components (message, thread-content,
  message-thread-full, etc.), reasoning display is already built-in. Just
  configure reasoning parameters in your dashboard and it works automatically.
</Callout>

### Custom Implementation

If building custom components, reasoning is available in the `ThreadMessage` type:

```typescript
interface ThreadMessage {
  id: string;
  content: string;
  role: "user" | "assistant";
  reasoning?: string[]; // Array of reasoning strings
  // ... other fields
}
```

Access it like any other message property:

```tsx
{
  message.reasoning?.map((step, index) => (
    <div key={index}>
      <strong>Step {index + 1}:</strong> {step}
    </div>
  ));
}
```

## Best Practices

### Performance Optimization

Balance reasoning effort with cost and latency in your dashboard configuration. See provider-specific pages for parameter details:

- **[OpenAI Configuration](/reference/providers/openai#provider-specific-parameters)** - Adjust `reasoningEffort` levels
- **[Google Configuration](/reference/providers/google#provider-specific-parameters)** - Optimize `thinkingBudget` values

**General Guidelines:**

- **Development**: Use maximum reasoning effort for thorough testing
- **Production**: Use balanced reasoning settings for most use cases
- **High-Volume**: Consider using non-reasoning models for simple queries

### Cost Considerations

Reasoning tokens are billed separately and typically cost more than standard tokens:

- **Monitor usage** - Track reasoning token consumption in your dashboard
- **Optimize effort** - Use lower reasoning settings when appropriate
- **Test different levels** - Compare quality vs. cost at different reasoning levels

## Troubleshooting

**Reasoning not appearing in responses?**

- Verify you're using a supported reasoning model (see [OpenAI](/reference/providers/openai) or [Google](/reference/providers/google) model lists)
- Check your dashboard settings under **LLM Providers** → **Custom LLM Parameters**
- Ensure reasoning parameters are properly configured (see provider-specific documentation)
- Click **Save Settings** after making changes

**Reasoning tokens consuming too many resources?**

- Lower your reasoning effort settings (see provider-specific parameter documentation)
- Create separate projects with different configurations for simple vs. complex queries
- Monitor token usage in your Tambo Cloud usage dashboard
- Consider using non-reasoning models for high-volume, simple tasks

## Additional Resources

- **[OpenAI Models](/reference/providers/openai)** - Complete OpenAI model list and reasoning configuration
- **[Google Models](/reference/providers/google)** - Complete Google model list and thinking configuration
- **[Custom LLM Parameters](/reference/providers/custom-llm-parameters)** - General parameter configuration guide
- **[Model Labels](/models/labels)** - Understanding model status and observed behaviors
